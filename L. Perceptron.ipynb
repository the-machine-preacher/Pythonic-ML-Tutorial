{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc666495",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 1. What is a Perceptron?\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "Similar to how atoms are the building blocks of matter and how microprocessors are the building blocks of a computer, perceptrons are the building blocks of Neural Networks.\n",
    "\n",
    "<br/>If you look closely, you might notice that the word “perceptron” is a combination of two words:\n",
    "- *Perception* (noun) the ability to sense something\n",
    "- *Neuron* (noun) a nerve cell in the human brain that turns sensory input into meaningful information\n",
    "\n",
    "<br/>Therefore, the perceptron is an artificial neuron that simulates the task of a biological neuron to solve problems through its own “sense” of the world.\n",
    "\n",
    "<br/>Although the perceptron comes with its own artificial design and set of parameters, at its core, a single perceptron is trying to make a simple decision.\n",
    "\n",
    "<br/>Let’s take the example a simple self-driving car that is based on a perceptron. If there’s an obstacle on the left, the car would have to steer right. Similarly, if there’s an obstacle on the right, the car would have to steer left.\n",
    "\n",
    "<br/>For this example, a perceptron could take the position of the obstacle as inputs, and produce a decision — left turn or right turn — based on those inputs.\n",
    "\n",
    "<br/>And here’s the cool part — the perceptron can correct itself based on the result of its decision to make better decisions in the future!\n",
    "\n",
    "<br/>Of course, the real world scenario isn’t that simple. But if you combine a bunch of such perceptrons, you will get a neural network that can even make better decisions on your behalf!\n",
    "<img src=\"Images/perceptron.webp\" style=\"width:800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7788e",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 2. Representing a Perceptron\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "So the perceptron is an artificial neuron that can make a simple decision. Let’s implement one from scratch in Python!\n",
    "\n",
    "<br/>The perceptron has three main components:\n",
    "- *Inputs:* Each input corresponds to a feature. For example, in the case of a person, features could be age, height, weight, college degree, etc.\n",
    "- *Weights:* Each input also has a weight which assigns a certain amount of importance to the input. If an input’s weight is large, it means this input plays a bigger role in determining the output. For example, a team’s skill level will have a bigger weight than the average age of players in determining the outcome of a match.\n",
    "- *Output:* Finally, the perceptron uses the inputs and weights to produce an output. The type of the output varies depending on the nature of the problem. For example, to predict whether or not it’s going to rain, the output has to be binary — 1 for Yes and 0 for No. However, to predict the temperature for the next day, the range of the output has to be larger — say a number from 70 to 90.\n",
    "\n",
    "<br/>*Exercise:*\n",
    "1. Our `Perceptron` class by default takes two inputs and a pre-defined weight for each input. Complete the `__init__()` method inside the `Perceptron` class by creating instance variables `self.num_inputs` and `self.weights` that represent the attributes of a `Perceptron` object. Assign the parameters `num_inputs` and `weights` to `self.num_inputs` and `self.weights` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9a4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "        # complete the default constructor method\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70744910",
   "metadata": {},
   "source": [
    "2. Create a `Perceptron` object called `cool_perceptron` (without any arguments) and print it out to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b844d542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Perceptron object at 0x000001C2C31588B0>\n"
     ]
    }
   ],
   "source": [
    "cool_perceptron = Perceptron()\n",
    "print(cool_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb6aa5",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 3. Step 1: Weighted Sum\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "Great! Now that you understand the structure of the perceptron, here’s an important question — how are the inputs and weights magically turned into an output? This is a two-step process, and the first step is finding the *weighted sum* of the inputs.\n",
    "\n",
    "What is the *weighted sum*? This is just a number that gives a reasonable representation of the inputs:\n",
    "> $ weighted sum=x_1w_1+x_2w_2+...+x_nw_n $\n",
    "\n",
    "<br/>The *x*‘s are the inputs and the *w*‘s are the weights.\n",
    "\n",
    "<br/>Here’s how we can implement it:\n",
    "- Start with a weighted sum of 0. Let’s call it `weighted_sum`.\n",
    "- Start with the first input and multiply it by its corresponding weight. Add this result to `weighted_sum`.\n",
    "- Go to the next input and multiply it by its corresponding weight. Add this result to `weighted_sum`.\n",
    "- Repeat this process for all inputs.\n",
    "\n",
    "<br/>*Exercise:*\n",
    "1. Create a variable called `weighted_sum` to hold the value of the weighted sum and set its starting value to `0`. Return `weighted_sum` outside the `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a598754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(self, inputs):\n",
    "    # Create variable to store weighted sum\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "        pass\n",
    "        # Complete this loop\n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73658d64",
   "metadata": {},
   "source": [
    "2. Let’s go through each input-weight pair and find the weighted sum using indexing. Delete the `pass` statement inside the for loop. For each iteration in the loop, find the product of the input and weight at index `i`, add the result to `weighted_sum`, and store it back in `weighted_sum` to update the value of `weighted_sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cc493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[2,1]):\n",
    "        # complete the default constructor method\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "    \n",
    "    def weighted_sum(self, inputs):\n",
    "        # create variable to store weighted sum\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs):\n",
    "            weighted_sum += self.weights[i]*inputs[i]\n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff5484",
   "metadata": {},
   "source": [
    "3. Outside the `Perceptron` class, after the Perceptron object `cool_perceptron` has been created, print out the weighted sum for the inputs `[24, 55]`. What is the weighted sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac4e35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "cool_perceptron = Perceptron()\n",
    "print(cool_perceptron.weighted_sum([24, 55]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c190f72f",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 4. Step 2: Activation Function\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "After finding the weighted sum, the second step is to *constrain the weighted sum* to produce a desired output.\n",
    "\n",
    "<br/>Why is that important? Imagine if a perceptron had inputs in the range of 100-1000 but the goal was to simply predict whether or not something would occur — `1` for “Yes” and `0` for “No”. This would result in a very large weighted sum.\n",
    "\n",
    "<br/>How can the perceptron produce a meaningful output in this case? This is exactly where *activation functions* come in! These are special functions that transform the weighted sum into a desired and constrained output.\n",
    "\n",
    "<br/>For example, if you want to train a perceptron to detect whether a point is above or below a line (which we will be doing in this lesson!), you might want the output to be a `+1` or `-1` label. For this task, you can use the “sign activation function” to help the perceptron make the decision:\n",
    "- If weighted sum is positive, return `+1`\n",
    "- If weighted sum is negative, return `-1`\n",
    "\n",
    "<br/>In this lesson, we will focus on using the sign activation function because it is the simplest way to get started with perceptrons and eventually visualize one in action.\n",
    "\n",
    "<br/>*Exercise:*\n",
    "1. Inside the `.activation()` method, return `1` if the `weighted_sum` is greater than or equal to `0`. Return `-1` if the `weighted_sum` is less than `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b88a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "    \n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs):\n",
    "            weighted_sum += self.weights[i]*inputs[i]\n",
    "        return weighted_sum\n",
    "  \n",
    "    def activation(self, weighted_sum):\n",
    "        #Complete this method\n",
    "        if weighted_sum >= 0: return 1\n",
    "        else: return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bccfbf9",
   "metadata": {},
   "source": [
    "3. Try it out for yourself! Print out the result of the method `.activation()` called on `cool_perceptron` if the weighted sum is `52`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ac0561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cool_perceptron = Perceptron()\n",
    "print(cool_perceptron.weighted_sum([24, 55]))\n",
    "print(cool_perceptron.activation(52))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302642c7",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 5. Training the Perceptron\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "Our perceptron can now make a prediction given inputs, but how do we know if it gets those predictions right?\n",
    "\n",
    "<br/>Right now we expect the perceptron to be very bad because it has random weights. We haven’t taught it anything yet, so we can’t expect it to get classifications correct! The good news is that we can train the perceptron to produce better and better results! In order to do this, we provide the perceptron a training set — a collection of random inputs with correctly predicted outputs.\n",
    "\n",
    "<br/>On the right, you can see a plot of scattered points with positive and negative labels. This is a simple training set.\n",
    "\n",
    "<br/>In the code, the training set has been represented as a dictionary with coordinates as keys and labels as values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9928766",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = {(18, 49): -1, (2, 17): 1, (24, 35): -1, (14, 26): 1, (17, 34): -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ecc19",
   "metadata": {},
   "source": [
    "We can measure the perceptron’s actual performance against this training set. By doing so, we get a sense of “how bad” the perceptron is. The goal is to gradually nudge the perceptron — by slightly changing its weights — towards a better version of itself that correctly matches all the input-output pairs in the training set.\n",
    "\n",
    "<br/>We will use these points to train the perceptron to correctly separate the positive labels from the negative labels by visualizing the perceptron as a line. Stay tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe48ed18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def generate_training_set(num_points):\n",
    "\tx_coordinates = [random.randint(0, 50) for i in range(num_points)]\n",
    "\ty_coordinates = [random.randint(0, 50) for i in range(num_points)]\n",
    "\ttraining_set = dict()\n",
    "\tfor x, y in zip(x_coordinates, y_coordinates):\n",
    "\t\tif x <= 45-y: training_set[(x,y)] = 1\n",
    "\t\telif x > 45-y: training_set[(x,y)] = -1\n",
    "\treturn training_set\n",
    "\n",
    "training_set = generate_training_set(30)\n",
    "\n",
    "x_plus = []\n",
    "y_plus = []\n",
    "x_minus = []\n",
    "y_minus = []\n",
    "\n",
    "for data in training_set:\n",
    "\tif training_set[data] == 1:\n",
    "\t\tx_plus.append(data[0])\n",
    "\t\ty_plus.append(data[1])\n",
    "\telif training_set[data] == -1:\n",
    "\t\tx_minus.append(data[0])\n",
    "\t\ty_minus.append(data[1])\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(-25, 75), ylim=(-25, 75))\n",
    "\n",
    "plt.scatter(x_plus, y_plus, marker = '+', c = 'green', s = 128, linewidth = 2)\n",
    "plt.scatter(x_minus, y_minus, marker = '_', c = 'red', s = 128, linewidth = 2)\n",
    "\n",
    "plt.title(\"Training Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf06a3",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 6. Training Error\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "Now that we have our training set, we can start feeding inputs into the perceptron and comparing the actual outputs against the expected labels!\n",
    "\n",
    "<br/>Every time the output mismatches the expected label, we say that the perceptron has made a *training error* — a quantity that measures “how bad” the perceptron is performing.\n",
    "\n",
    "<br/>As mentioned in the last exercise, the goal is to nudge the perceptron towards zero training error. The training error is calculated by subtracting the predicted label value from the actual label value.\n",
    "> $ training\\_error=actual\\_label−predicted\\_label $\n",
    "\n",
    "<br/>For each point in the training set, the perceptron either produces a `+1` or a `-1` (as we are using the Sign Activation Function). Since the labels are also a `+1` or a `-1`, there are four different possibilities for the error the perceptron makes:\n",
    "<img src=\"Images/training_error.png\" style=\"width:800px\">\n",
    "\n",
    "<br/>These training error values will be crucial in improving the perceptron’s performance as we will see in the upcoming exercises.\n",
    "\n",
    "<br/>*Exercise:*\n",
    "1. In the `.training()` method, let’s find the perceptron’s error on each inputs in `training_set`. First, we need the perceptron’s predicted output for a point. Inside the `for` loop, create a variable called `prediction` and assign it the correct label value using `.activation()`, `.weighted_sum()`, and `inputs` in a single statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54895db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "    \n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs): weighted_sum += self.weights[i]*inputs[i]\n",
    "        return weighted_sum\n",
    "  \n",
    "    def activation(self, weighted_sum):\n",
    "        if weighted_sum >= 0: return 1\n",
    "        if weighted_sum < 0: return -1\n",
    "    \n",
    "    def training(self, training_set):\n",
    "        for inputs in training_set: prediction = self.activation(self.weighted_sum(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084eb1e1",
   "metadata": {},
   "source": [
    "2. Create a variable named `actual` and assign it the actual label for each `inputs` in `training_set`. Then create a variable called `error` and assign it the value of `actual - prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04ba7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "    \n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs): weighted_sum += self.weights[i]*inputs[i]\n",
    "        return weighted_sum\n",
    "  \n",
    "    def activation(self, weighted_sum):\n",
    "        if weighted_sum >= 0: return 1\n",
    "        if weighted_sum < 0: return -1\n",
    "    \n",
    "    def training(self, training_set):\n",
    "        for inputs in training_set: prediction = self.activation(self.weighted_sum(inputs))\n",
    "        actual = training_set[inputs]\n",
    "        error = actual - prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c8405",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 7. Tweaking the Weights\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "What do we do once we have the errors for the perceptron? We slowly nudge the perceptron towards a better version of itself that eventually has zero error.\n",
    "\n",
    "<br/>The only way to do that is to change the parameters that define the perceptron. We can’t change the inputs so the only thing that can be tweaked are the weights. As we change the weights, the outputs change as well.\n",
    "\n",
    "<br/>The goal is to find the optimal combination of weights that will produce the correct output for as many points as possible in the dataset.\n",
    "<img src=\"Images/tweaking_the_weights.webp\" style=\"width:800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40090cb7",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 8. The Perceptron Algorithm\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "But one question still remains — how do we tweak the weights optimally? We can’t just play around randomly with the weights until the correct combination magically pops up. There needs to be a way to guarantee that the perceptron improves its performance over time.\n",
    "\n",
    "<br/>This is where the *Perceptron Algorithm* comes in. The math behind why this works is outside the scope of this lesson, so we’ll directly apply the algorithm to optimally tweak the weights and nudge the perceptron towards zero error.\n",
    "\n",
    "<br/>The most important part of the algorithm is the update rule where the weights get updated:\n",
    "> $ weight=weight+(error∗input) $\n",
    "\n",
    "<br/>We keep on tweaking the weights until all possible labels are correctly predicted by the perceptron. This means that multiple passes might need to be made through the `training_set` before the Perceptron Algorithm comes to a halt.\n",
    "\n",
    "<br/>In this exercise, you will continue to work on the `.training()` method. We have made the following changes to this method from the last exercise:\n",
    "- `foundLine = False` (a boolean that indicates whether the perceptron has found a line to separate the positive and negative labels)\n",
    "- `while not foundLine:` (a while loop that continues to train the perceptron until the line is found)\n",
    "- `total_error = 0` (to count the total error the perceptron makes in each round)\n",
    "- `total_error += abs(error)` (to update the total error the perceptron makes in each round)\n",
    "\n",
    "<br/>*Exercise:*\n",
    "1. If the algorithm doesn’t find an error, the perceptron must have correctly predicted the labels for all points. Outside the `for` loop (but inside the `while` loop), change the value of `foundLine` to `True` if `total_error` equals `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f920cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "    \n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs): weighted_sum += self.weights[i]*inputs[i]\n",
    "        return weighted_sum\n",
    "  \n",
    "    def activation(self, weighted_sum):\n",
    "        if weighted_sum >= 0: return 1\n",
    "        if weighted_sum < 0: return -1\n",
    "    \n",
    "    def training(self, training_set):\n",
    "        foundLine = False\n",
    "        while not foundLine:\n",
    "            total_error = 0\n",
    "            for inputs in training_set:\n",
    "                prediction = self.activation(self.weighted_sum(inputs))\n",
    "                actual = training_set[inputs]\n",
    "                error = actual - prediction\n",
    "                total_error += abs(error)\n",
    "            if total_error == 0: foundLine = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae5696",
   "metadata": {},
   "source": [
    "2. In order to update the weight for each inputs, create another `for` loop (inside the existing `for` loop) that iterates a loop variable `i` through a `range` of `self.num_inputs`. And inside the second `for` loop, update each weight `self.weights[i]` by applying the update rule:\n",
    "> $ weight=weight+(error∗inputs) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09fa7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "    \n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs): weighted_sum += self.weights[i]*inputs[i]\n",
    "        return weighted_sum\n",
    "  \n",
    "    def activation(self, weighted_sum):\n",
    "        if weighted_sum >= 0: return 1\n",
    "        if weighted_sum < 0: return -1\n",
    "    \n",
    "    def training(self, training_set):\n",
    "        foundLine = False\n",
    "        while not foundLine:\n",
    "            total_error = 0\n",
    "            for inputs in training_set:\n",
    "                prediction = self.activation(self.weighted_sum(inputs))\n",
    "                actual = training_set[inputs]\n",
    "                error = actual - prediction\n",
    "                total_error += abs(error)\n",
    "                for i in range(self.num_inputs): self.weights[i] = self.weights[i] + (error*inputs[i])\n",
    "            if total_error == 0: foundLine = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651e767",
   "metadata": {},
   "source": [
    "3. Great job! Now give it a try for yourself. Train `cool_perceptron` using `small_training_set`. You can also print out the optimal weights to see for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad31022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5, 1]\n"
     ]
    }
   ],
   "source": [
    "cool_perceptron = Perceptron()\n",
    "small_training_set = {(0,3):1, (3,0):-1, (0,-3):-1, (-3,0):1}\n",
    "cool_perceptron.training(small_training_set)\n",
    "print(cool_perceptron.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf236fa0",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 9. The Bias Weight\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "You have understood that the perceptron can be trained to produce correct outputs by tweaking the regular weights.\n",
    "\n",
    "<br/>However, there are times when a minor adjustment is needed for the perceptron to be more accurate. This supporting role is played by the bias weight. It takes a default input value of 1 and some random weight value.\n",
    "\n",
    "<br/>So now the weighted sum equation should look like:\n",
    "> $ weighted\\_sum=x_1w_1+x_2w_2+...+x_nw_n+1w_b $\n",
    "\n",
    "<br/>How does this change the code so far? You only have to consider two small changes:\n",
    "- Add a 1 to the set of inputs (now there are 3 inputs instead of 2)\n",
    "- Add a bias weight to the list of weights (now there are 3 weights instead of 2)\n",
    "\n",
    "<br/>We’ll automatically make these replacements in the code so you should be good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5249528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=3, weights=[1,1,1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "    \n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs): weighted_sum += self.weights[i]*inputs[i]\n",
    "        return weighted_sum\n",
    "  \n",
    "    def activation(self, weighted_sum):\n",
    "        if weighted_sum >= 0: return 1\n",
    "        if weighted_sum < 0: return -1\n",
    "    \n",
    "    def training(self, training_set):\n",
    "        foundLine = False\n",
    "        while not foundLine:\n",
    "            total_error = 0\n",
    "            for inputs in training_set:\n",
    "                prediction = self.activation(self.weighted_sum(inputs))\n",
    "                actual = training_set[inputs]\n",
    "                error = actual - prediction\n",
    "                total_error += abs(error)\n",
    "                for i in range(self.num_inputs): self.weights[i] = self.weights[i] + (error*inputs[i])\n",
    "            if total_error == 0: foundLine = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dc7ab",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 10. Representing a Line\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "So far so good! The perceptron works as expected, but everything seems to be taking place behind the scenes. What if we could visualize the perceptron’s training process to gain a better understanding of what’s going on?\n",
    "\n",
    "<br/>The weights change throughout the training process so if only we could meaningfully visualize those weights…\n",
    "\n",
    "<br/>Turns out we can! In fact, it gets better. The weights can actually be used to represent a line! This greatly simplifies our visualization.\n",
    "\n",
    "<br/>You might know that a line can be represented using the slope-intercept form. A perceptron’s weights can be used to find the slope and intercept of the line that the perceptron represents.\n",
    "- `slope = -self.weights[0]/self.weights[1]`\n",
    "- `intercept = -self.weights[2]/self.weights[1]`\n",
    "\n",
    "<br/>The explanation for these equations is beyond the scope of this lesson, so we’ll just use them to visualize the perceptron for now.\n",
    "\n",
    "<br/>In the plot below, you should be able to see a line that represents the perceptron in its first iteration of the training process.\n",
    "<img src=\"Images/perceptron_representing_a_line.webp\" style=\"width:800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30d6d4",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 11. Finding a Linear Classifier\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "Let’s recap what you just learned!\n",
    "\n",
    "<br/>The perceptron has inputs, weights, and an output. The weights are parameters that define the perceptron and they can be used to represent a line. In other words, the perceptron can be visualized as a line.\n",
    "\n",
    "<br/>What does it mean for the perceptron to correctly classify every point in the training set?\n",
    "\n",
    "<br/>Theoretically, it means that the perceptron predicted every label correctly.\n",
    "\n",
    "<br/>Visually, it means that the perceptron found a *linear classifier*, or a *decision boundary*, that separates the two distinct set of points in the training set.\n",
    "\n",
    "<br/>In the plot below, you should be able to see the *linear classifier* that was found by the perceptron in the last iteration of the training process.\n",
    "<img src=\"Images/finding_a_linear_classifier.gif\" style=\"width:800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af363df",
   "metadata": {},
   "source": [
    "<img src=\"Images/atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 12. What's Next? Neural Networks\n",
    "*in Machine Learning*\n",
    "\n",
    "----\n",
    "Congratulations! You have now built your own perceptron from scratch.\n",
    "\n",
    "<br/>Let’s step back and think about what you just accomplished and see if there are any limits to a single perceptron.\n",
    "\n",
    "<br/>Earlier, the data points in the training set were *linearly separable* i.e. a single line could easily separate the two dissimilar sets of points.\n",
    "\n",
    "<br/>What would happen if the data points were scattered in such a way that a line could no longer classify the points? A single perceptron with only two inputs wouldn’t work for such a scenario because it cannot represent a non-linear decision boundary.\n",
    "\n",
    "<br/>That’s when more perceptrons and features come into play!\n",
    "\n",
    "<br/>By increasing the number of features and perceptrons, we can give rise to the Multilayer Perceptrons, also known as Neural Networks, which can solve much more complicated problems.\n",
    "\n",
    "<br/>With a solid understanding of perceptrons, you are now ready to dive into the incredible world of Neural Networks!\n",
    "<img src=\"Images/neural-net-image.svg\" style=\"width:800px\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
